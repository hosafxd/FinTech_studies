{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85858b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "/* Overwrite the hard-coded white background for ipywidgets */\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    "/* Set widget foreground text and color to match the VS Code dark theme */\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0b395",
   "metadata": {},
   "source": [
    "### üìñ Sections\n",
    "\n",
    "#### 1.) üé≤ Random and Uncertain Systems\n",
    "\n",
    "- Random Systems\n",
    "\n",
    "- Uncertain Systems\n",
    "\n",
    "#### 2.) üé∞ Games of Chance and Incomplete Information\n",
    "\n",
    "- Games of Chance\n",
    "\n",
    "- Games of Incomplete Information\n",
    "\n",
    "- Optimal Policy Functions\n",
    "\n",
    "#### 3.) üçÖ Groceries Shopping and Trading\n",
    "\n",
    "- Grocery Shopping as a Max EV Problem\n",
    "\n",
    "- Trading as a Max EV Problem\n",
    "\n",
    "- If Trading is Gambling, so is Grocery Shopping\n",
    "\n",
    "#### 4.) üí≠ Closing Thoughts and Future Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181b698",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641789e",
   "metadata": {},
   "source": [
    "#### 1.) üé≤ Random and Uncertain Systems\n",
    "\n",
    "##### Random Variables and Stochastic Processes\n",
    "\n",
    "Anytime we are dealing with a random system, probabilities and statistics converge\n",
    "\n",
    "This means probabilities *literally* represent the expected proportion of outcomes observed\n",
    "\n",
    "This goes for both random variables and stochastic processes (which are just random variables over an index)\n",
    "\n",
    "$$X \\sim \\text{Uniform}\\{1,2,3,4,5,6\\} \\quad\\quad P(X = k) = \\frac{1}{6},\\; k \\in \\{1,2,3,4,5,6\\} \\quad\\quad F_X(x) = \\frac{\\lfloor x \\rfloor}{6}\\;\\;\\; \\text{for } 1 \\leq x < 6\\;\\quad \\varphi_X(t) = \\frac{1}{6} \\sum_{k=1}^6 e^{i k t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452dc485",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253973c5",
   "metadata": {},
   "source": [
    "##### Population vs Empirical Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4782e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Setup ---\n",
    "die_faces = np.arange(1, 7)\n",
    "pmf_theoretical = np.ones(6) / 6  # true population distribution (uniform)\n",
    "n_trials = 30\n",
    "np.random.seed(42)\n",
    "rolls = np.random.choice(die_faces, size=n_trials, replace=True)\n",
    "\n",
    "# --- Helper: construct figure for a given step ---\n",
    "def make_empirical_convergence_fig(step):\n",
    "    drawn = rolls[step]\n",
    "    counts = np.bincount(rolls[:step+1], minlength=7)[1:]  # exclude index 0\n",
    "    empirical_pmf = counts / (step + 1)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        subplot_titles=(\"Probability Mass Function\", \"Empirical Mass Function\"),\n",
    "    )\n",
    "\n",
    "    # --- Left subplot: true PMF ---\n",
    "    bar_colors = ['#39ff14'] * 6  # neon green\n",
    "    border_colors = ['rgba(0,0,0,0)'] * 6\n",
    "    border_widths = [0] * 6\n",
    "    bar_idx = drawn - 1\n",
    "    border_colors[bar_idx] = '#FFD700'\n",
    "    border_widths[bar_idx] = 5\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=die_faces,\n",
    "            y=pmf_theoretical,\n",
    "            width=0.5,\n",
    "            marker=dict(color=bar_colors, line=dict(color=border_colors, width=border_widths)),\n",
    "            name=\"Dice Roll Probability\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Right subplot: empirical PMF over time ---\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=die_faces,\n",
    "            y=empirical_pmf,\n",
    "            width=0.5,\n",
    "            marker=dict(color='#00ffff', opacity=0.8),\n",
    "            name=\"Empirical Distribution\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Overlay theoretical PMF on the right for comparison ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=die_faces,\n",
    "            y=pmf_theoretical,\n",
    "            mode='lines',\n",
    "            line=dict(color='#ff00ff', width=3, dash='dash'),\n",
    "            name=\"Theoretical Distribution\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Legend-only traces ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='lines',\n",
    "            line=dict(color='#39ff14', width=4),\n",
    "            name=\"Dice Roll Probability\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='lines',\n",
    "            line=dict(color='#00ffff', width=4),\n",
    "            name=\"Empirical Distribution\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Axes ---\n",
    "    fig.update_xaxes(title_text=\"Die Face\", row=1, col=1, range=[0.5, 6.5], tickvals=die_faces)\n",
    "    fig.update_yaxes(title_text=\"True P(X=x)\", row=1, col=1, range=[0, 0.25])\n",
    "    fig.update_xaxes(title_text=\"Die Face\", row=1, col=2, range=[0.5, 6.5], tickvals=die_faces)\n",
    "    fig.update_yaxes(title_text=\"Empirical P(X=x)\", row=1, col=2, range=[0, 0.25])\n",
    "\n",
    "    # --- Subtle gridlines ---\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "    # --- Layout ---\n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        title_text=\"Population Distribution vs Empirical Distribution\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            x=0.97, y=0.97,\n",
    "            xanchor='right', yanchor='top',\n",
    "            orientation='v',\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "            borderwidth=0,\n",
    "            font=dict(color='white', size=14)\n",
    "        ),\n",
    "        margin=dict(l=50, r=20, b=80, t=70),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames ---\n",
    "frames = [\n",
    "    go.Frame(data=make_empirical_convergence_fig(step).data, name=str(step))\n",
    "    for step in range(n_trials)\n",
    "]\n",
    "\n",
    "# --- Initial figure ---\n",
    "fig = make_empirical_convergence_fig(0)\n",
    "fig.frames = frames\n",
    "\n",
    "# --- Play button ---\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.1,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 20, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b8c97d",
   "metadata": {},
   "source": [
    "**Remark:** The empirical distribution is just the plot of realizations or draws from the population distribution.  Small samples don't reflect the population distribution well, larger samples do.  However, this is only the case if crucially, the population distribution does not change over time.  In other words, we are iteratively rolling the same die, it will not change over time on an uncertain schedule.  If it changed over time at a random schedule (defined) it would still represent the population distribution well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a055b82",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ca780",
   "metadata": {},
   "source": [
    "##### Law of Large Numbers (LLN) Statistical Convergence\n",
    "\n",
    "All random variables have population statistics that tell us something about the shape and relative location of the distribution\n",
    "\n",
    "$$M_X(t) = \\mathbb{E}[e^{tX}] = \\sum_{k=1}^6 e^{tk} \\cdot \\frac{1}{6} \\quad\\quad M_X'(0) = \\mathbb{E}[X] = 3.5$$\n",
    "\n",
    "\n",
    "$$\\text{Mean} = 3.5 \\quad\\quad \\text{Variance} = \\frac{35}{12} \\quad\\quad \\text{Skewness} = 0 \\quad\\quad \\text{Kurtosis} = -\\frac{6}{5}$$\n",
    "\n",
    "The Law of Large Numbers (LLN) ensures that repeated sampling from a fixed distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c39e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Set style\n",
    "die_faces = np.arange(1, 7)\n",
    "pmf_theoretical = np.ones(6)/6\n",
    "n_trials = 100\n",
    "np.random.seed(42)\n",
    "rolls = np.random.choice(die_faces, size=n_trials, replace=True)\n",
    "\n",
    "# Prepare means for LLN\n",
    "means = np.cumsum(rolls) / np.arange(1, n_trials+1)\n",
    "\n",
    "# Helper: construct figure for a given step\n",
    "def make_lln_dice_fig(step):\n",
    "    drawn = rolls[step]\n",
    "    means_until_now = means[:step+1]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        subplot_titles=(\"Probability Mass Function\", \"Law of Large Numbers: Mean of Rolls\")\n",
    "    )\n",
    "\n",
    "    # PMF Bar Colors and Borders\n",
    "    bar_colors = ['#39ff14']*6  # neon green\n",
    "    border_widths = [0]*6\n",
    "    border_colors = ['rgba(0,0,0,0)']*6\n",
    "    bar_idx = drawn - 1\n",
    "    border_widths[bar_idx] = 4\n",
    "    border_colors[bar_idx] = '#ffd600'  # bright yellow border\n",
    "\n",
    "    # Left subplot: PMF bars (no legend entry here)\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=die_faces,\n",
    "            y=pmf_theoretical,\n",
    "            width=0.5,\n",
    "            marker=dict(color=bar_colors, line=dict(width=border_widths, color=border_colors)),\n",
    "            name=\"PMF\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Right subplot: cumulative mean (no legend entry here)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.arange(1, step+2),\n",
    "            y=means_until_now,\n",
    "            mode='lines',\n",
    "            line=dict(color='#00ffff', width=4),  # neon cyan\n",
    "            name=\"Cumulative Mean (live)\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Theoretical mean line (no legend entry)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[1, n_trials],\n",
    "            y=[np.mean(die_faces)]*2,\n",
    "            mode='lines',\n",
    "            line=dict(color='#FFD600', width=2, dash='dash'),\n",
    "            name=\"Theoretical Mean\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Legend-only traces, added to the RIGHT subplot ---\n",
    "    # Green legend entry: Dice Roll Probability\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],  # legend-only\n",
    "            mode='lines',\n",
    "            line=dict(color='#39ff14', width=4),\n",
    "            name=\"Dice Roll Probability\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Cyan legend entry: Cumulative Mean\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],  # legend-only\n",
    "            mode='lines',\n",
    "            line=dict(color='#00ffff', width=4),\n",
    "            name=\"Cumulative Mean\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Axes\n",
    "    fig.update_xaxes(title_text=\"Die Face\", row=1, col=1, range=[0.5,6.5], tickmode='array', tickvals=die_faces)\n",
    "    fig.update_yaxes(title_text=\"P(X=x)\", row=1, col=1, range=[0, 0.22])\n",
    "    fig.update_xaxes(title_text=\"Number of Rolls (n)\", row=1, col=2, range=[0, n_trials+1])\n",
    "    fig.update_yaxes(title_text=\"Sample Mean\", row=1, col=2, range=[0.8,6.2])\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "\n",
    "    # Layout with overlaid, stacked legend on the right subplot\n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        title_text=\"Law of Large Numbers on a Fair Die\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            x=0.97, y=0.97,              # inside the right subplot area\n",
    "            xanchor='right', yanchor='top',\n",
    "            orientation='v',              # stacked\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "            borderwidth=0,\n",
    "            font=dict(color='white', size=14)\n",
    "        ),\n",
    "        margin=dict(l=50, r=20, b=80, t=70),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# -- Animate frames\n",
    "frames = [go.Frame(data=make_lln_dice_fig(step).data, name=str(step)) for step in range(n_trials)]\n",
    "\n",
    "# Initial figure\n",
    "fig = make_lln_dice_fig(0)\n",
    "fig.frames = frames\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.1,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 40, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9dc7e5",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________\n",
    "\n",
    "##### Law of Large Numbers (LLN), Probabalistic, and Distribution Convergence\n",
    "\n",
    "\n",
    "The Law of Large Numbers (LLN) ensures that for any threshold x, the empirical CDF converges to the true CDF as the sample size increases.\n",
    " \n",
    "$$\\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{1}\\{X_i \\leq x\\} \\xrightarrow{n \\to \\infty} F(x) = P(X \\leq x)$$\n",
    "\n",
    "This works because for each x, the empirical CDF is just the average of Bernoulli indicators 1{X_i ‚â§ x}, which by the LLN converges to P(X ‚â§ x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b10ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Setup ---\n",
    "die_faces = np.arange(1, 7)\n",
    "pmf_theoretical = np.ones(6) / 6  # true population distribution (uniform)\n",
    "n_trials = 500\n",
    "np.random.seed(42)\n",
    "rolls = np.random.choice(die_faces, size=n_trials, replace=True)\n",
    "\n",
    "# --- Helper: construct figure for a given step ---\n",
    "def make_empirical_convergence_fig(step):\n",
    "    drawn = rolls[step]\n",
    "    counts = np.bincount(rolls[:step+1], minlength=7)[1:]  # exclude index 0\n",
    "    empirical_pmf = counts / (step + 1)\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1,\n",
    "        cols=2,\n",
    "        column_widths=[0.5, 0.5],\n",
    "        subplot_titles=(\"Probability Mass Function\", \"Empirical Mass Function\"),\n",
    "    )\n",
    "\n",
    "    # --- Left subplot: true PMF ---\n",
    "    bar_colors = ['#39ff14'] * 6  # neon green\n",
    "    border_colors = ['rgba(0,0,0,0)'] * 6\n",
    "    border_widths = [0] * 6\n",
    "    bar_idx = drawn - 1\n",
    "    border_colors[bar_idx] = '#FFD700'\n",
    "    border_widths[bar_idx] = 5\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=die_faces,\n",
    "            y=pmf_theoretical,\n",
    "            width=0.5,\n",
    "            marker=dict(color=bar_colors, line=dict(color=border_colors, width=border_widths)),\n",
    "            name=\"Dice Roll Probability\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Right subplot: empirical PMF over time ---\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=die_faces,\n",
    "            y=empirical_pmf,\n",
    "            width=0.5,\n",
    "            marker=dict(color='#00ffff', opacity=0.8),\n",
    "            name=\"Empirical Distribution\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Overlay theoretical PMF on the right for comparison ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=die_faces,\n",
    "            y=pmf_theoretical,\n",
    "            mode='lines',\n",
    "            line=dict(color='#ff00ff', width=3, dash='dash'),\n",
    "            name=\"Theoretical Distribution\",\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Legend-only traces ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='lines',\n",
    "            line=dict(color='#39ff14', width=4),\n",
    "            name=\"Dice Roll Probability\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None], y=[None],\n",
    "            mode='lines',\n",
    "            line=dict(color='#00ffff', width=4),\n",
    "            name=\"Empirical Distribution\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Axes ---\n",
    "    fig.update_xaxes(title_text=\"Die Face\", row=1, col=1, range=[0.5, 6.5], tickvals=die_faces)\n",
    "    fig.update_yaxes(title_text=\"True P(X=x)\", row=1, col=1, range=[0, 0.25])\n",
    "    fig.update_xaxes(title_text=\"Die Face\", row=1, col=2, range=[0.5, 6.5], tickvals=die_faces)\n",
    "    fig.update_yaxes(title_text=\"Empirical P(X=x)\", row=1, col=2, range=[0, 0.25])\n",
    "\n",
    "    # --- Subtle gridlines ---\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "    # --- Layout ---\n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        title_text=\"Convergence of Empirical Distribution to Population Distribution\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            x=0.97, y=0.97,\n",
    "            xanchor='right', yanchor='top',\n",
    "            orientation='v',\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "            borderwidth=0,\n",
    "            font=dict(color='white', size=14)\n",
    "        ),\n",
    "        margin=dict(l=50, r=20, b=80, t=70),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames ---\n",
    "frames = [\n",
    "    go.Frame(data=make_empirical_convergence_fig(step).data, name=str(step))\n",
    "    for step in range(n_trials)\n",
    "]\n",
    "\n",
    "# --- Initial figure ---\n",
    "fig = make_empirical_convergence_fig(0)\n",
    "fig.frames = frames\n",
    "\n",
    "# --- Play button ---\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.1,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 20, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9e8b42",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9356ac9",
   "metadata": {},
   "source": [
    "##### Statistics Inform Decision Making in Randomness\n",
    "\n",
    "Probabilities and statistics of stochastic processes also converge by the law of large numbers\n",
    "\n",
    "Consider a game where we are trading the outcome of a dice roll, we make the market and set the bid/offer. . .\n",
    "\n",
    "$$W_n = \\sum_{i=1}^n \\left( X_i - P_i \\right), \\quad \\text{where } X_i \\sim \\text{DieRoll},\\; P_i = \\begin{cases} 4 & \\text{if buy} \\\\ 2 & \\text{if sell} \\end{cases}$$\n",
    "\n",
    "Assume a 50/50 probability of buying or selling, by the law of total expectation. . .\n",
    "\n",
    "$$\\mathbb{E}[P/L] = \\mathbb{E}[P/L| Long]P(Long) + \\mathbb{E}[P/L| Short]P(Short) = (4 - \\mathbb{E}[X])(.5) + (\\mathbb{E}[X] - 2)(.5) = \\$.5 $$\n",
    "\n",
    "This is our edge, if we trade 100 times in this random system we will on average accumulate $50 of wealth. . .\n",
    "\n",
    "$$\\$.5 \\text{ per roll} \\times 100 \\text{ trades} = \\$50 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4781b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Parameters ---\n",
    "np.random.seed(42)\n",
    "n_steps = 100\n",
    "bid, ask = 3, 4  # fair quotes around expected value (3.5)\n",
    "die_faces = np.arange(1, 7)\n",
    "n_samples = 10  # number of extra sample paths\n",
    "\n",
    "# --- Simulate main sample path (used for animation) ---\n",
    "directions = np.random.choice([-1, 1], size=n_steps)\n",
    "executed_prices = np.where(directions == 1, bid, ask)\n",
    "outcomes = np.random.choice(die_faces, size=n_steps)\n",
    "trade_pnl = np.where(directions == 1, outcomes - bid, ask - outcomes)\n",
    "wealth = np.cumsum(trade_pnl)\n",
    "\n",
    "# --- Theoretical EV line ---\n",
    "avg_ev_per_trade = 0.5  # theoretical EV per trade\n",
    "expected_wealth = np.linspace(avg_ev_per_trade, avg_ev_per_trade * n_steps, n_steps)\n",
    "\n",
    "# --- Generate extra sample paths for comparison ---\n",
    "sample_paths = []\n",
    "for i in range(n_samples):\n",
    "    dirs = np.random.choice([-1, 1], size=n_steps)\n",
    "    outs = np.random.choice(die_faces, size=n_steps)\n",
    "    pnl = np.where(dirs == 1, outs - bid, ask - outs)\n",
    "    sample_paths.append(np.cumsum(pnl))\n",
    "\n",
    "# --- Opacity gradient for sample paths ---\n",
    "opacities = np.linspace(0.15, 0.8, n_samples)\n",
    "\n",
    "# --- Precompute global wealth Y range for right subplot to keep plots steady ---\n",
    "all_paths = [wealth] + sample_paths + [expected_wealth]\n",
    "ymin = min([path.min() for path in all_paths])\n",
    "ymax = max([path.max() for path in all_paths])\n",
    "y_margin = (ymax - ymin) * 0.05\n",
    "y_range = [ymin - y_margin, ymax + y_margin]\n",
    "\n",
    "\n",
    "# --- Helper: build one frame ---\n",
    "def make_market_fig(step):\n",
    "    side = \"Long @ Bid (3)\" if directions[step] == 1 else \"Short @ Ask (4)\"\n",
    "    roll = outcomes[step]\n",
    "    pnl = trade_pnl[step]\n",
    "    wealth_until_now = wealth[:step + 1]\n",
    "\n",
    "    # Expanding window for x_range in right subplot\n",
    "    x_max = step + 2 if step + 2 > 10 else 10\n",
    "    x_range = [0, x_max]\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        column_widths=[0.4, 0.6],\n",
    "        subplot_titles=(\"Market Side & Outcome\", \"Wealth Paths vs Theoretical EV\")\n",
    "    )\n",
    "\n",
    "    # --- Left chart: Bid/Ask sides ---\n",
    "    bar_colors = ['#39ff14', '#ff073a']  # neon green (bid), neon red (ask)\n",
    "    sides = [\"Long @ Bid (3)\", \"Short @ Ask (4)\"]\n",
    "    border_colors = ['rgba(0,0,0,0)'] * 2\n",
    "    border_widths = [0, 0]\n",
    "    idx = sides.index(side)\n",
    "    border_colors[idx] = '#FFD700'  # highlight current side\n",
    "    border_widths[idx] = 5\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            x=sides,\n",
    "            y=[0.5, 0.5],\n",
    "            marker=dict(color=bar_colors,\n",
    "                        line=dict(color=border_colors, width=border_widths)),\n",
    "            showlegend=False,\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Add outcome and P/L annotation ---\n",
    "    fig.add_annotation(\n",
    "        text=f\"üé≤ Outcome = <b>{roll}</b><br>üí∞ Market Maker P/L = <b>{pnl:+.2f}</b>\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=1.1,\n",
    "        showarrow=False,\n",
    "        font=dict(size=18, color=\"white\"),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # --- Right chart: sample paths ---\n",
    "    for i, path in enumerate(sample_paths):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.arange(1, step + 2),\n",
    "                y=path[:step + 1],\n",
    "                mode='lines',\n",
    "                line=dict(color=f'rgba(0,255,255,{opacities[i]:.2f})', width=1.5),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "    # --- Primary observed wealth path ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.arange(1, step + 2),\n",
    "            y=wealth_until_now,\n",
    "            mode='lines+markers',\n",
    "            line=dict(color='#00bfff', width=4),\n",
    "            marker=dict(size=6, color='#00bfff'),\n",
    "            name=\"Observed Path\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Theoretical EV line ---\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.arange(1, n_steps + 1),\n",
    "            y=expected_wealth,\n",
    "            mode='lines',\n",
    "            line=dict(color='#ff00ff', width=4, dash='dash'),\n",
    "            name=\"Theoretical Path\",\n",
    "            showlegend=True\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # --- Axes and layout styling ---\n",
    "    fig.update_xaxes(title_text=\"Trade Side\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Probability\", row=1, col=1, range=[0, 1])\n",
    "    fig.update_xaxes(title_text=\"Trade Number (n)\", row=1, col=2, range=x_range)\n",
    "    fig.update_yaxes(title_text=\"Cumulative Wealth\", row=1, col=2, range=y_range)\n",
    "    fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "    fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        title_text=\"Market Making: Convergence of Multiple Wealth Paths to Expected Value\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            x=0.75, y=0.95,\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "            font=dict(color='white', size=14)\n",
    "        ),\n",
    "        margin=dict(l=50, r=20, b=80, t=70),\n",
    "    )\n",
    "    return fig, x_range\n",
    "\n",
    "\n",
    "# --- Build initial figure ---\n",
    "fig, _ = make_market_fig(0)\n",
    "\n",
    "# --- Create animation frames (data + limited layout updates) ---\n",
    "frames = []\n",
    "for step in range(n_steps):\n",
    "    step_fig, x_range = make_market_fig(step)\n",
    "    frames.append(go.Frame(\n",
    "        data=step_fig.data,\n",
    "        name=str(step),\n",
    "        layout=go.Layout(xaxis2=dict(range=x_range))  # only adjust right subplot xlim\n",
    "    ))\n",
    "\n",
    "fig.frames = frames\n",
    "\n",
    "# --- Play button setup ---\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.1,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 30, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': .01}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3aa5f",
   "metadata": {},
   "source": [
    "**Remark:** This isn't a course on stochastic processes but this will only be true if the system is ergodic (i.e. time average = ensemble average), I have a video on this topic in the context of optimal bet sizing (additive vs multiplicative processes) that I will link in the video description below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69806aaa",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab35964",
   "metadata": {},
   "source": [
    "##### Uncertain Systems\n",
    "\n",
    "In random systems we observe convergence in probabilities, statistics, and distributions. . .\n",
    "\n",
    "In uncertain systems, we observe *do not* observe this behavior - a great source of confusion for both students and folks new to the space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70babbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "n_steps = 200\n",
    "initial_wealth = 1000\n",
    "bet_size = 25\n",
    "n_paths = 14  # More paths to show more non-stationary cases\n",
    "\n",
    "# --- LEFT: Positive EV (Random system - convergence to mean) ---\n",
    "left_p_win = 0.60  # 60% win\n",
    "left_ev = bet_size * (left_p_win - (1 - left_p_win))\n",
    "pos_ev_paths = np.zeros((n_paths, n_steps))\n",
    "pos_ev_paths[:, 0] = initial_wealth\n",
    "for path in range(n_paths):\n",
    "    wins = np.random.random(n_steps) < left_p_win\n",
    "    for i in range(1, n_steps):\n",
    "        pos_ev_paths[path, i] = pos_ev_paths[path, i-1] + (bet_size if wins[i] else -bet_size)\n",
    "pos_ev_line = initial_wealth + np.arange(n_steps) * left_ev\n",
    "\n",
    "# --- RIGHT: Non-stationary system: time-varying EV within each path ---\n",
    "# For greater variance, increase spread and amplitude of starting/ending p_win and ensure some wild time-variation.\n",
    "# We'll let starting p_wins range lower/higher, and use larger wave amplitude.\n",
    "\n",
    "# Broader range for greater variance\n",
    "right_p_win_start = np.linspace(0.10, 0.85, n_paths)\n",
    "right_p_win_end   = np.linspace(0.85, 0.10, n_paths)  # Reverse for max spread/high variance\n",
    "\n",
    "nonstationary_paths = np.zeros((n_paths, n_steps))\n",
    "nonstationary_paths[:, 0] = initial_wealth\n",
    "\n",
    "# For one path, make the 'red dashed' highlight (e.g. middle path)\n",
    "highlight_path_idx = n_paths // 2\n",
    "\n",
    "# For legend at end, store EV over time for highlight path\n",
    "highlight_path_evs = []\n",
    "\n",
    "for idx in range(n_paths):\n",
    "    # For each path, p_win varies as either wild up, down, or big amplitude sine/cos\n",
    "    if idx % 3 == 0:\n",
    "        # Linear variation with even more extreme start & end\n",
    "        p_win = np.linspace(right_p_win_start[idx], right_p_win_end[idx], n_steps)\n",
    "    elif idx % 3 == 1:\n",
    "        # Linear down (opposite)\n",
    "        p_win = np.linspace(right_p_win_end[idx], right_p_win_start[idx], n_steps)\n",
    "    else:\n",
    "        # Very large amplitude sinusoidal oscillation within [0.05,0.95]\n",
    "        amp = 0.45  # amplitude (nearly full interval)\n",
    "        mid = 0.5 + np.random.uniform(-0.15, 0.15)\n",
    "        freq = 1 + np.random.uniform(-0.25, 0.25)  # some randomness to frequency\n",
    "        p_win = np.clip(\n",
    "            mid + amp * np.sin(np.linspace(0, np.pi * 2 * freq, n_steps) + np.random.uniform(-2,2)),\n",
    "            0.05, 0.95\n",
    "        )\n",
    "    wins = np.random.random(n_steps) < p_win\n",
    "    for i in range(1, n_steps):\n",
    "        # Increase realized variance by adding noise to outcome with some big 'shock' steps\n",
    "        shock = 0\n",
    "        if np.random.rand() < 0.03:  # ~3% chance of a wild outcome\n",
    "            shock = np.random.choice([2, -2]) * bet_size  # Big move up or down!\n",
    "        nonstationary_paths[idx, i] = nonstationary_paths[idx, i-1] + (bet_size if wins[i] else -bet_size) + shock\n",
    "    if idx == highlight_path_idx:\n",
    "        highlight_path_evs = bet_size * (p_win*2 - 1)  # Save EV(t) for annotation if wanted\n",
    "\n",
    "# --- Animation Frames ---\n",
    "frames = []\n",
    "for i in range(1, n_steps):\n",
    "    frame_data = []\n",
    "    # Left: random system, positive edge, convergence\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - (path * (0.7/n_paths))\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=pos_ev_paths[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='green', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x', yaxis='y',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=np.arange(i+1),\n",
    "            y=pos_ev_line[:i+1],\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash', width=3),\n",
    "            xaxis='x', yaxis='y',\n",
    "            name='EV (Positive)',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    # Right: non-stationary, each path's EV changes in time\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - (path * (0.7/n_paths))\n",
    "        if path == highlight_path_idx:\n",
    "            # Red dashed highlight\n",
    "            frame_data.append(\n",
    "                go.Scatter(\n",
    "                    x=np.arange(i+1),\n",
    "                    y=nonstationary_paths[path, :i+1],\n",
    "                    mode='lines',\n",
    "                    line=dict(\n",
    "                        color='red',  # Red\n",
    "                        width=4,\n",
    "                        dash='dash'\n",
    "                    ),\n",
    "                    opacity=1.0,\n",
    "                    xaxis='x2', yaxis='y2',\n",
    "                    name='Non-stationary Example',\n",
    "                    showlegend=(i == n_steps-1)\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            frame_data.append(\n",
    "                go.Scatter(\n",
    "                    x=np.arange(i+1),\n",
    "                    y=nonstationary_paths[path, :i+1],\n",
    "                    mode='lines',\n",
    "                    line=dict(\n",
    "                        color='#B266FF',  # Neon purple-ish; use a strong neon purple\n",
    "                        width=2\n",
    "                    ),\n",
    "                    opacity=opacity,\n",
    "                    xaxis='x2', yaxis='y2',\n",
    "                    name=None,\n",
    "                    showlegend=False\n",
    "                )\n",
    "            )\n",
    "    frames.append(go.Frame(\n",
    "        name=f'frame{i}',\n",
    "        data=frame_data,\n",
    "        layout=go.Layout(xaxis=dict(range=[0, n_steps]), xaxis2=dict(range=[0, n_steps]))\n",
    "    ))\n",
    "\n",
    "# --- Build initial traces for the animated figure ---\n",
    "fig_nonstat = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\n",
    "        \"Random/Ergodic Process (Positive EV & Convergence)\",\n",
    "        \"Non-stationary Process (EV Shifts Over Time)\"\n",
    "    ),\n",
    "    column_widths=[0.5, 0.5]\n",
    ")\n",
    "# LEFT: positive EV sample paths & EV line\n",
    "for path in range(n_paths):\n",
    "    fig_nonstat.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0],\n",
    "            y=[initial_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='green', width=2),\n",
    "            opacity=1.0 - path * (0.7/n_paths),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "fig_nonstat.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0],\n",
    "        y=[initial_wealth],\n",
    "        mode='lines',\n",
    "        line=dict(color='orange', dash='dash', width=3),\n",
    "        name='EV (Positive)',\n",
    "        showlegend=True\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "# RIGHT: non-stationary, different time-varying EVs per path\n",
    "for path in range(n_paths):\n",
    "    if path == highlight_path_idx:\n",
    "        fig_nonstat.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0],\n",
    "                y=[initial_wealth],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', dash='dash', width=4),\n",
    "                name='Non-stationary Example',\n",
    "                showlegend=True\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "    else:\n",
    "        fig_nonstat.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[0],\n",
    "                y=[initial_wealth],\n",
    "                mode='lines',\n",
    "                line=dict(color='#B266FF', width=2),  # neon purple lines\n",
    "                opacity=1.0 - path * (0.7/n_paths),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "fig_nonstat.frames = frames\n",
    "\n",
    "fig_nonstat.update_layout(\n",
    "    height=550,\n",
    "    width=1000,\n",
    "    title_text=\"Random Convergence (Positive EV) vs Non-stationary Process (No Statistical Convergence!)\",\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color='white'),\n",
    "    legend=dict(orientation='h', y=-0.15, x=0.5, xanchor='center'),\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.05, 'y': -0.17,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 10, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig_nonstat.update_xaxes(title_text=\"Round\", range=[0, n_steps],\n",
    "    showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "fig_nonstat.update_yaxes(title_text=\"Wealth\", range=[0, 2000],\n",
    "    showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "fig_nonstat.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea90dc6",
   "metadata": {},
   "source": [
    "##### This is where things get tricky.  Statistics we run on data can be misleading because they *change over time*\n",
    "\n",
    "Instead of more samples leading to convergence (like in random systems), more samples may correspond to *different* statistics\n",
    "\n",
    "This is why the trading space is so confusing - past performance isn't indicative of future performance\n",
    "\n",
    "Nothing converges, no probabilities, no statistics, no distributions, everything changes over time\n",
    "\n",
    "We need to change the way we think about these statistics now depending on the context and our goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c5b25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e47886",
   "metadata": {},
   "source": [
    "#### 2.) üé∞ Games of Chance and Incomplete Information\n",
    "\n",
    "We can discuss the idea of **edge** and the application to random and uncertain systems\n",
    "\n",
    "We never know the outcome of *one* event in either a **random** or **uncertain** system, so how do we make decisions?\n",
    "\n",
    "How our wealth evolves over time is dictated by our edge or EV, we can compute it by the Law of Total Expectation (LoTE) below. . .\n",
    " \n",
    " The Law of Total Expectation (for a discrete partition $\\{B_i\\}$ of the sample space) is given by:\n",
    " \n",
    " $$\\mathbb{E}[X] = \\sum_{i} \\mathbb{E}[X\\mid B_i] \\cdot \\mathbb{P}(B_i)$$\n",
    " \n",
    " where $X$ is a random variable, and $\\{B_i\\}$ is a partition of the sample space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Simulation setup ---\n",
    "n_steps = 100\n",
    "initial_wealth = 1000\n",
    "bet_size = 25\n",
    "n_paths = 10\n",
    "\n",
    "# Positive EV (60% win rate)\n",
    "pos_ev_paths = np.zeros((n_paths, n_steps))\n",
    "pos_ev_paths[:, 0] = initial_wealth\n",
    "for path in range(n_paths):\n",
    "    pos_ev_wins = np.random.random(n_steps) < 0.60\n",
    "    for i in range(1, n_steps):\n",
    "        pos_ev_paths[path, i] = pos_ev_paths[path, i-1] + (bet_size if pos_ev_wins[i] else -bet_size)\n",
    "\n",
    "# Negative EV (40% win rate)\n",
    "neg_ev_paths = np.zeros((n_paths, n_steps))\n",
    "neg_ev_paths[:, 0] = initial_wealth\n",
    "for path in range(n_paths):\n",
    "    neg_ev_wins = np.random.random(n_steps) < 0.40\n",
    "    for i in range(1, n_steps):\n",
    "        neg_ev_paths[path, i] = neg_ev_paths[path, i-1] + (bet_size if neg_ev_wins[i] else -bet_size)\n",
    "\n",
    "# Expected Value lines\n",
    "pos_ev_line = initial_wealth + np.arange(n_steps) * bet_size * (0.60 - 0.40)\n",
    "neg_ev_line = initial_wealth + np.arange(n_steps) * bet_size * (0.40 - 0.60)\n",
    "\n",
    "# --- Frames ---\n",
    "frames = []\n",
    "for i in range(1, n_steps):\n",
    "    frame_data = []\n",
    "\n",
    "    # Left (Positive EV)\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - (path * 0.07)\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=pos_ev_paths[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='green', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x', yaxis='y',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    # Add expected value line\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=np.arange(i+1),\n",
    "            y=pos_ev_line[:i+1],\n",
    "            mode='lines',\n",
    "            line=dict(color='lime', dash='dash', width=3),\n",
    "            xaxis='x', yaxis='y',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Right (Negative EV)\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - (path * 0.07)\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=neg_ev_paths[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x2', yaxis='y2',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    # Add expected value line\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=np.arange(i+1),\n",
    "            y=neg_ev_line[:i+1],\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash', width=3),\n",
    "            xaxis='x2', yaxis='y2',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    frames.append(go.Frame(\n",
    "        name=f\"frame{i}\",\n",
    "        data=frame_data,\n",
    "        layout=go.Layout(\n",
    "            xaxis=dict(range=[0, n_steps]),\n",
    "            xaxis2=dict(range=[0, n_steps]),\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# --- Figure ---\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=('Positive EV (edge > 0)', 'Negative EV (edge < 0)'),\n",
    "    column_widths=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Initial left-side traces\n",
    "for path in range(n_paths):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0], y=[initial_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='green', width=2),\n",
    "            opacity=1.0 - path * 0.07,\n",
    "            name='Positive EV Path' if path == 0 else None,\n",
    "            showlegend=(path == 0)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Initial right-side traces\n",
    "for path in range(n_paths):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0], y=[initial_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=2),\n",
    "            opacity=1.0 - path * 0.07,\n",
    "            name='Negative EV Path' if path == 0 else None,\n",
    "            showlegend=(path == 0)\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Add static expected value lines\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(n_steps), y=pos_ev_line, mode='lines',\n",
    "               line=dict(color='lime', dash='dash', width=3),\n",
    "               name='Expected Value (Positive EV)'),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=np.arange(n_steps), y=neg_ev_line, mode='lines',\n",
    "               line=dict(color='orange', dash='dash', width=3),\n",
    "               name='Expected Value (Negative EV)'),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# --- Apply frames ---\n",
    "fig.frames = frames\n",
    "\n",
    "# --- Layout ---\n",
    "fig.update_layout(\n",
    "    height=550,\n",
    "    width=1100,\n",
    "    title_text=\"Wealth Paths: Positive vs Negative Expected Value<br><sup>Dashed line = Theoretical EV</sup>\",\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color='white'),\n",
    "    showlegend=True,\n",
    "    legend=dict(orientation='h', y=-0.2, x=0.5, xanchor='center'),\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.05, 'y': -0.1,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 30, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "# --- Axes ---\n",
    "fig.update_xaxes(title_text=\"Round\", range=[0, n_steps],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "fig.update_yaxes(title_text=\"Wealth\", range=[0, 2000],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829f493f",
   "metadata": {},
   "source": [
    "##### Well Then, What Dictates Our Expected Value?\n",
    "\n",
    "**The system itself or our actions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9224d9d9",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63086177",
   "metadata": {},
   "source": [
    "##### Policy Functions\n",
    "\n",
    "Depending on the system we are operating in, we may be able to influence our expected value (EV) or edge with *our own actions*\n",
    "\n",
    "The function $\\pi$ represents **a collection of actions given the current state of the system** and dictates what action we end up taking\n",
    "\n",
    "$$\\pi^* = \\arg\\max_\\pi \\mathbb{E}[R \\mid \\pi]$$\n",
    "\n",
    "Just because we act optimally, it does not mean we will have positive EV at this point in time\n",
    "\n",
    "Moreover, the optimal policy may change over time depending on the system!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1915f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Shared parameters ---\n",
    "n_policies = 100\n",
    "policy_vals = np.linspace(0, 1, n_policies)\n",
    "n_steps = 60\n",
    "n_paths = 8\n",
    "init_wealth = 1000\n",
    "bet_unit = 25\n",
    "win_prob_optimal = 0.6      # Optimal: positive EV\n",
    "win_prob_subopt = 0.45      # Suboptimal: negative EV, for demonstration\n",
    "\n",
    "# ----------- POLICY FUNCTIONS (EV curves) ----------------\n",
    "\n",
    "# -- Optimal (positive edge) quadratic policy --\n",
    "a1 = 2.8\n",
    "h1 = 0.58\n",
    "k1 = 0.20\n",
    "evs_opt = -a1*(policy_vals - h1)**2 + k1\n",
    "opt_idx = np.argmax(evs_opt)\n",
    "opt_policy = policy_vals[opt_idx]\n",
    "opt_ev = evs_opt[opt_idx]\n",
    "\n",
    "# -- Suboptimal (negative edge) quadratic policy --\n",
    "# Keep quadratic, just shift downward and toward more negative max\n",
    "a2 = 2.8\n",
    "h2 = 0.45\n",
    "k2 = -0.08\n",
    "evs_subopt = -a2*(policy_vals - h2)**2 + k2\n",
    "subopt_idx = np.argmax(evs_subopt)\n",
    "subopt_policy = policy_vals[subopt_idx]\n",
    "subopt_ev = evs_subopt[subopt_idx]\n",
    "\n",
    "# ----------- WEALTH PATHS (for optimal/suboptimal) ------------\n",
    "\n",
    "# -- Sample wealth paths for optimal policy --\n",
    "paths_opt = np.zeros((n_paths, n_steps))\n",
    "paths_opt[:, 0] = init_wealth\n",
    "for path in range(n_paths):\n",
    "    for i in range(1, n_steps):\n",
    "        do_bet = np.random.random() < opt_policy\n",
    "        if do_bet:\n",
    "            win = np.random.random() < win_prob_optimal\n",
    "            change = bet_unit if win else -bet_unit\n",
    "        else:\n",
    "            change = 0\n",
    "        paths_opt[path, i] = paths_opt[path, i-1] + change\n",
    "\n",
    "# -- Sample wealth paths for suboptimal (negative EV) policy --\n",
    "paths_subopt = np.zeros((n_paths, n_steps))\n",
    "paths_subopt[:, 0] = init_wealth\n",
    "for path in range(n_paths):\n",
    "    for i in range(1, n_steps):\n",
    "        do_bet = np.random.random() < subopt_policy\n",
    "        if do_bet:\n",
    "            win = np.random.random() < win_prob_subopt\n",
    "            change = bet_unit if win else -bet_unit\n",
    "        else:\n",
    "            change = 0\n",
    "        paths_subopt[path, i] = paths_subopt[path, i-1] + change\n",
    "\n",
    "# ----------- POLICY & STAR TRACES (LEFT) --------------\n",
    "policy_curve_trace_opt = go.Scatter(\n",
    "    x=policy_vals, y=evs_opt,\n",
    "    mode='lines',\n",
    "    line=dict(color='royalblue', width=3),\n",
    "    name='Expected Value by Policy',\n",
    "    xaxis='x', yaxis='y',\n",
    "    showlegend=True\n",
    ")\n",
    "policy_star_trace_opt = go.Scatter(\n",
    "    x=[opt_policy], y=[opt_ev],\n",
    "    mode='markers+text',\n",
    "    marker=dict(symbol='star', size=24, color='gold', line=dict(color='black', width=2)),\n",
    "    text=['Optimal Policy'],\n",
    "    textposition='top center',\n",
    "    showlegend=False,\n",
    "    xaxis='x', yaxis='y'\n",
    ")\n",
    "\n",
    "policy_curve_trace_sub = go.Scatter(\n",
    "    x=policy_vals, y=evs_subopt,\n",
    "    mode='lines',\n",
    "    line=dict(color='crimson', width=3),\n",
    "    name='Expected Value by Policy',\n",
    "    xaxis='x3', yaxis='y3',\n",
    "    showlegend=True\n",
    ")\n",
    "policy_star_trace_sub = go.Scatter(\n",
    "    x=[subopt_policy], y=[subopt_ev],\n",
    "    mode='markers+text',\n",
    "    marker=dict(symbol='star', size=24, color='orange', line=dict(color='black', width=2)),\n",
    "    text=['Policy Chosen'],\n",
    "    textposition='top center',\n",
    "    showlegend=False,\n",
    "    xaxis='x3', yaxis='y3'\n",
    ")\n",
    "\n",
    "# ----------- ANIMATION FRAMES (for both upper and lower subplots) ------------\n",
    "\n",
    "policy_ylim_pad = 0.2\n",
    "frames = []\n",
    "for i in range(1, n_steps):\n",
    "    frame_data = []\n",
    "    # --- Top row: optimal policy ---\n",
    "    frame_data.append(policy_curve_trace_opt)\n",
    "    frame_data.append(policy_star_trace_opt)\n",
    "    # Wealth path animations (right subplot 1, row 1 col 2)\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - path * 0.07\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=paths_opt[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='green', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x2', yaxis='y2',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=[0, i],\n",
    "            y=[init_wealth, init_wealth + i * opt_policy * (2 * win_prob_optimal - 1) * bet_unit],\n",
    "            mode='lines',\n",
    "            line=dict(color='lime', dash='dash', width=3),\n",
    "            xaxis='x2', yaxis='y2',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- Lower row: suboptimal policy ---\n",
    "    frame_data.append(policy_curve_trace_sub)\n",
    "    frame_data.append(policy_star_trace_sub)\n",
    "    # Wealth path animations (right subplot 2, row 2 col 2)\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - path * 0.07\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=paths_subopt[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='firebrick', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x4', yaxis='y4',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=[0, i],\n",
    "            y=[init_wealth, init_wealth + i * subopt_policy * (2 * win_prob_subopt - 1) * bet_unit],\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash', width=3),\n",
    "            xaxis='x4', yaxis='y4',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    frames.append(go.Frame(\n",
    "        name=f\"f{i}\",\n",
    "        data=frame_data,\n",
    "        layout=go.Layout(\n",
    "            xaxis=dict(range=[0, 1], showgrid=True, gridcolor='rgba(128,128,128,0.3)'),  # top left\n",
    "            yaxis=dict(\n",
    "                range=[evs_opt.min() - 0.05 - policy_ylim_pad, evs_opt.max() + 0.05 + policy_ylim_pad],\n",
    "                showgrid=True,\n",
    "                gridcolor='rgba(128,128,128,0.3)'\n",
    "            ),\n",
    "            xaxis2=dict(range=[0, n_steps], showgrid=True, gridcolor='rgba(128,128,128,0.3)'), # top right\n",
    "            yaxis2=dict(range=[0, 2000], showgrid=True, gridcolor='rgba(128,128,128,0.3)'),\n",
    "            xaxis3=dict(range=[0, 1], showgrid=True, gridcolor='rgba(128,128,128,0.3)'),      # bottom left\n",
    "            yaxis3=dict(\n",
    "                range=[evs_subopt.min() - 0.05 - policy_ylim_pad, evs_subopt.max() + 0.05 + policy_ylim_pad],\n",
    "                showgrid=True,\n",
    "                gridcolor='rgba(128,128,128,0.3)'\n",
    "            ),\n",
    "            xaxis4=dict(range=[0, n_steps], showgrid=True, gridcolor='rgba(128,128,128,0.3)'), # bottom right\n",
    "            yaxis4=dict(range=[0, 2000], showgrid=True, gridcolor='rgba(128,128,128,0.3)'),\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# ----------- FIGURE: 2x2 subplots -------------------------\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    subplot_titles=[\n",
    "        'Policy Function (Optimal ‚Äî Positive EV)', f'Sample Wealth Paths (Optimal Policy = {opt_policy:.2f})',\n",
    "        'Policy Function (Suboptimal ‚Äî Negative EV)', f'Sample Wealth Paths (Suboptimal Policy = {subopt_policy:.2f})'\n",
    "    ],\n",
    "    horizontal_spacing=0.13,\n",
    "    vertical_spacing=0.17\n",
    ")\n",
    "\n",
    "# --- Top row: optimal (positive edge) ---\n",
    "fig.add_trace(policy_curve_trace_opt, row=1, col=1)\n",
    "fig.add_trace(policy_star_trace_opt, row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Policy (P(bet))\", range=[0, 1],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=1, col=1)\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Expected Value per Play\",\n",
    "    range=[evs_opt.min() - policy_ylim_pad, evs_opt.max() + policy_ylim_pad],\n",
    "    showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "    row=1, col=1)\n",
    "for path in range(n_paths):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0],\n",
    "            y=[init_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='green', width=2),\n",
    "            opacity=1.0 - path * 0.07,\n",
    "            name='Sample Wealth Path' if path == 0 else None,\n",
    "            showlegend=(path == 0)\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, n_steps-1],\n",
    "        y=[init_wealth, init_wealth + (n_steps-1)*opt_policy*(2*win_prob_optimal - 1)*bet_unit],\n",
    "        mode='lines',\n",
    "        line=dict(color='lime', dash='dash', width=3),\n",
    "        name='Expected Value'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Round\", range=[0, n_steps],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Wealth\", range=[0, 2000],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=1, col=2)\n",
    "\n",
    "# --- Bottom row: suboptimal (negative edge) ---\n",
    "fig.add_trace(policy_curve_trace_sub, row=2, col=1)\n",
    "fig.add_trace(policy_star_trace_sub, row=2, col=1)\n",
    "fig.update_xaxes(title_text=\"Policy (P(bet))\", range=[0, 1],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=2, col=1)\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Expected Value per Play\",\n",
    "    range=[evs_subopt.min() - policy_ylim_pad, evs_subopt.max() + policy_ylim_pad],\n",
    "    showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "    row=2, col=1)\n",
    "for path in range(n_paths):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0],\n",
    "            y=[init_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='firebrick', width=2),\n",
    "            opacity=1.0 - path * 0.07,\n",
    "            name='Sample Wealth Path (Neg EV)' if path == 0 else None,\n",
    "            showlegend=(path == 0)\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, n_steps-1],\n",
    "        y=[init_wealth, init_wealth + (n_steps-1)*subopt_policy*(2*win_prob_subopt - 1)*bet_unit],\n",
    "        mode='lines',\n",
    "        line=dict(color='orange', dash='dash', width=3),\n",
    "        name='Expected Value (Neg EV)'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "fig.update_xaxes(title_text=\"Round\", range=[0, n_steps],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"Wealth\", range=[0, 2000],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=2, col=2)\n",
    "\n",
    "# ----------- Layout/Attachment for animation -----------\n",
    "fig.frames = frames\n",
    "fig.update_layout(\n",
    "    height=860, width=1000,\n",
    "    plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color='white'),\n",
    "    title_text=\"Comparison: Positive vs Negative EV Policy Function & Wealth Paths (Animated)\",\n",
    "    showlegend=True,\n",
    "    legend=dict(orientation='h', y=-0.21, x=0.51, xanchor='center'),\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.07, 'y': -0.13,\n",
    "        'showactive': False,\n",
    "        'buttons': [dict(\n",
    "            label='Play',\n",
    "            method='animate',\n",
    "            args=[None, {\n",
    "                'frame': {'duration': 40, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        )]\n",
    "    }]\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd4f4f5",
   "metadata": {},
   "source": [
    "**Key Point:** Optimal actions in a policy function guide overall expected value (EV) or edge in a positive direction - but it doesn't make it positive outright.  Positive EV (having an edge) is the accumulation of a set of optimal actions continuously updated over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04512205",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce25e9",
   "metadata": {},
   "source": [
    "##### Games of Chance (Random System, Fixed Negative Edge: Gambling)\n",
    "\n",
    "*Gambling* occurs when you **willfully and unnecessarily** engage with a system that has a fixed negative edge against you\n",
    "\n",
    "This is a game of chance, and where all the negative connotations of gambling should come from\n",
    "\n",
    "No matter what you do, no matter the policy function $\\pi$, if you continue to engage with that system you are certain to lose all of your money\n",
    "\n",
    " **Examples:**\n",
    " - Roulette\n",
    " - Slots\n",
    " - Craps\n",
    " - Lottery Tickets\n",
    "\n",
    "\n",
    "Effectively, the unconditional edge and edge conditional on your policy funciton are equivalent\n",
    "\n",
    "$$\\mathbb{E}[X] = \\sum_{i} \\mathbb{E}[X\\mid B_i] \\cdot \\mathbb{P}(B_i) = \\mathbb{E}[X \\mid \\pi^*]$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d51fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "n_steps = 100\n",
    "initial_wealth = 1000\n",
    "bet_size = 25\n",
    "n_paths = 10\n",
    "\n",
    "# --- Simulate unconditional edge (always bet, policy doesn't matter) ---\n",
    "neg_ev_paths_uncond = np.zeros((n_paths, n_steps))\n",
    "neg_ev_paths_uncond[:, 0] = initial_wealth\n",
    "for path in range(n_paths):\n",
    "    neg_ev_wins = np.random.random(n_steps) < 0.40  # 40% win probability\n",
    "    for i in range(1, n_steps):\n",
    "        neg_ev_paths_uncond[path, i] = neg_ev_paths_uncond[path, i-1] + (bet_size if neg_ev_wins[i] else -bet_size)\n",
    "neg_ev_line = initial_wealth + np.arange(n_steps) * bet_size * (0.40 - 0.60)\n",
    "\n",
    "# --- Simulate \"policy\" edge (skip 50% of rounds at random, still negative EV) ---\n",
    "neg_ev_paths_cond = np.zeros((n_paths, n_steps))\n",
    "neg_ev_paths_cond[:, 0] = initial_wealth\n",
    "all_take_actions = []\n",
    "for path in range(n_paths):\n",
    "    neg_ev_wins = np.random.random(n_steps) < 0.40  # 40% win\n",
    "    take_action = np.random.random(n_steps) < 0.5    # only bet half the time at random\n",
    "    all_take_actions.append(take_action)\n",
    "    for i in range(1, n_steps):\n",
    "        if take_action[i]:\n",
    "            neg_ev_paths_cond[path, i] = neg_ev_paths_cond[path, i-1] + (bet_size if neg_ev_wins[i] else -bet_size)\n",
    "        else:\n",
    "            neg_ev_paths_cond[path, i] = neg_ev_paths_cond[path, i-1]  # sit out\n",
    "\n",
    "# --- Prepare expected value lines per frame (for animation) ---\n",
    "# For unconditional, every round is a bet: EV is linear\n",
    "neg_ev_line_frames = initial_wealth + np.arange(n_steps) * bet_size * (0.40 - 0.60)\n",
    "\n",
    "# For conditional, use the *first* random skip pattern for the animation (to be repeatable)\n",
    "take_action_anim = all_take_actions[0]\n",
    "rounds_participated_anim = np.cumsum(take_action_anim)\n",
    "neg_ev_line_cond_frames = initial_wealth + rounds_participated_anim * bet_size * (0.40 - 0.60)\n",
    "\n",
    "# --- Build animation frames ---\n",
    "frames = []\n",
    "for i in range(1, n_steps):\n",
    "    frame_data = []\n",
    "    # Left: unconditional\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - (path * 0.07)\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=neg_ev_paths_uncond[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x',\n",
    "                yaxis='y',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    # Left: expected value line\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=np.arange(i+1),\n",
    "            y=neg_ev_line_frames[:i+1],\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash', width=3),\n",
    "            xaxis='x',\n",
    "            yaxis='y',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    # Right: conditional/skipped rounds\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - (path * 0.07)\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=neg_ev_paths_cond[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x2',\n",
    "                yaxis='y2',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    # Right: expected value line (conditional policy)\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=np.arange(i+1),\n",
    "            y=neg_ev_line_cond_frames[:i+1],\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash', width=3),\n",
    "            xaxis='x2',\n",
    "            yaxis='y2',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    frames.append(go.Frame(\n",
    "        name=f'frame{i}',\n",
    "        data=frame_data,\n",
    "        layout=go.Layout(xaxis=dict(range=[0, n_steps]),\n",
    "                         xaxis2=dict(range=[0, n_steps]))\n",
    "    ))\n",
    "\n",
    "# --- Build the initial animated figure ---\n",
    "fig_ev = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\n",
    "        \"Unconditional Edge (Always Bet)\",\n",
    "        \"Conditional Edge (Change Policy, Still Negative EV)\"\n",
    "    ),\n",
    "    column_widths=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Initial unconditional traces (left)\n",
    "for path in range(n_paths):\n",
    "    fig_ev.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0],\n",
    "            y=[initial_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=2),\n",
    "            opacity=1.0 - path * 0.07,\n",
    "            name='Path' if path == 0 else None,\n",
    "            showlegend=(path == 0)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "# Initial unconditional expected value line\n",
    "fig_ev.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0],\n",
    "        y=[initial_wealth],\n",
    "        mode='lines',\n",
    "        line=dict(color='orange', dash='dash', width=3),\n",
    "        name='EV (Unconditional)',\n",
    "        showlegend=True\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Initial conditional traces (right)\n",
    "for path in range(n_paths):\n",
    "    fig_ev.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0],\n",
    "            y=[initial_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=2),\n",
    "            opacity=1.0 - path * 0.07,\n",
    "            name='Path' if path == 0 else None,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "# Initial conditional expected value line\n",
    "fig_ev.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0],\n",
    "        y=[initial_wealth],\n",
    "        mode='lines',\n",
    "        line=dict(color='orange', dash='dash', width=3),\n",
    "        name='EV (Conditional)',\n",
    "        showlegend=True\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig_ev.frames = frames\n",
    "\n",
    "# --- Layout ---\n",
    "fig_ev.update_layout(\n",
    "    height=550,\n",
    "    width=1100,\n",
    "    title_text=\"Negative Expected Value: Unconditional vs Conditional Edge<br><sup>Your policy function cannot overcome a negative edge</sup>\",\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color='white'),\n",
    "    legend=dict(orientation='h', y=-0.15, x=0.5, xanchor='center'),\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.05, 'y': -0.17,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 30, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig_ev.update_xaxes(title_text=\"Round\", range=[0, n_steps],\n",
    "                    showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "fig_ev.update_yaxes(title_text=\"Wealth\", range=[0, 2000],\n",
    "                    showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "fig_ev.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2568f8",
   "metadata": {},
   "source": [
    "There is no optimal set of actions to accumulate wealth in these systems - your optimal action is not engaging in these systems\n",
    "\n",
    "*Remark:* This is not a class on stochastic processes but I have to make the remark that this is not a comment on ergodicity.  I have a video discussing this topic in the context of optimal bet sizing (additive vs multiplicative bets) - I will leave a link to it in the description below if you are interested in this topic and how it's connected to this idea of accumulating edge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364bc5c",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018aa17f",
   "metadata": {},
   "source": [
    "#### Games of Incomplete Information\n",
    "\n",
    "Unlike gambling and games of chance, we can act with a policy function $\\pi$ that dictates the trajectory of our wealth over time\n",
    "\n",
    "Crucially, in these systems we don't observe convergence (No LLN) - everything changes over time, including our optimal set of actions ($\\pi^*$)!\n",
    "\n",
    "**Examples:**\n",
    " - Election Betting\n",
    " - Sports Betting\n",
    " - Poker \n",
    " - Trading\n",
    " - Grocery Shopping?\n",
    "\n",
    " More specifically, \n",
    " \n",
    " The unconditional expectation of the system (or conditional on random action) **IS NOT** equal to the expectation conditional on our policy function! \n",
    " \n",
    "$$\\mathbb{E}[X] = \\sum_{i} \\mathbb{E}[X\\mid B_i] \\cdot \\mathbb{P}(B_i) \\neq \\mathbb{E}[X \\mid \\pi^*]$$\n",
    "\n",
    "**In other words, our actions influence the trajectory of our wealth path!  Unlike in a game of chance or gambling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be742a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Simulation Parameters ---\n",
    "n_steps = 100\n",
    "initial_wealth = 1000\n",
    "bet_size = 25\n",
    "n_paths = 10\n",
    "\n",
    "# --- Simulate negative EV (always bet, policy doesn't matter): left subplot ---\n",
    "neg_ev_paths_uncond = np.zeros((n_paths, n_steps))\n",
    "neg_ev_paths_uncond[:, 0] = initial_wealth\n",
    "for path in range(n_paths):\n",
    "    neg_ev_wins = np.random.random(n_steps) < 0.40  # 40% win probability (negative edge)\n",
    "    for i in range(1, n_steps):\n",
    "        neg_ev_paths_uncond[path, i] = neg_ev_paths_uncond[path, i-1] + (bet_size if neg_ev_wins[i] else -bet_size)\n",
    "neg_ev_line = initial_wealth + np.arange(n_steps) * bet_size * (0.40 - 0.60)\n",
    "\n",
    "# --- Simulate positive EV for conditional/policy edge (right subplot): player can accumulate wealth ---\n",
    "pos_ev_paths_cond = np.zeros((n_paths, n_steps))\n",
    "pos_ev_paths_cond[:, 0] = initial_wealth\n",
    "all_take_actions_pos = []\n",
    "for path in range(n_paths):\n",
    "    pos_ev_wins = np.random.random(n_steps) < 0.60  # 60% win probability (positive edge)\n",
    "    take_action = np.random.random(n_steps) < 0.5    # still bet half the time at random\n",
    "    all_take_actions_pos.append(take_action)\n",
    "    for i in range(1, n_steps):\n",
    "        if take_action[i]:\n",
    "            pos_ev_paths_cond[path, i] = pos_ev_paths_cond[path, i-1] + (bet_size if pos_ev_wins[i] else -bet_size)\n",
    "        else:\n",
    "            pos_ev_paths_cond[path, i] = pos_ev_paths_cond[path, i-1]  # sit out\n",
    "\n",
    "# --- Prepare expected value lines per frame (for animation) ---\n",
    "# For unconditional (left): negative EV\n",
    "neg_ev_line_frames = initial_wealth + np.arange(n_steps) * bet_size * (0.40 - 0.60)\n",
    "\n",
    "# For conditional (right): positive EV, use first skip pattern for animation\n",
    "take_action_anim_pos = all_take_actions_pos[0]\n",
    "rounds_participated_anim_pos = np.cumsum(take_action_anim_pos)\n",
    "pos_ev_line_cond_frames = initial_wealth + rounds_participated_anim_pos * bet_size * (0.60 - 0.40)\n",
    "\n",
    "# --- Build animation frames ---\n",
    "frames = []\n",
    "for i in range(1, n_steps):\n",
    "    frame_data = []\n",
    "    # Left: unconditional (always negative EV)\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - (path * 0.07)\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=neg_ev_paths_uncond[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='red', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x',\n",
    "                yaxis='y',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    # Left: expected value line\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=np.arange(i+1),\n",
    "            y=neg_ev_line_frames[:i+1],\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', dash='dash', width=3),\n",
    "            xaxis='x',\n",
    "            yaxis='y',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    # Right: conditional/policy (POSITIVE EV!)\n",
    "    for path in range(n_paths):\n",
    "        opacity = 1.0 - (path * 0.07)\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i+1),\n",
    "                y=pos_ev_paths_cond[path, :i+1],\n",
    "                mode='lines',\n",
    "                line=dict(color='green', width=2),\n",
    "                opacity=opacity,\n",
    "                xaxis='x2',\n",
    "                yaxis='y2',\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "    # Right: expected value line (conditional positive EV policy)\n",
    "    frame_data.append(\n",
    "        go.Scatter(\n",
    "            x=np.arange(i+1),\n",
    "            y=pos_ev_line_cond_frames[:i+1],\n",
    "            mode='lines',\n",
    "            line=dict(color='lime', dash='dash', width=3),\n",
    "            xaxis='x2',\n",
    "            yaxis='y2',\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "    frames.append(go.Frame(\n",
    "        name=f'frame{i}',\n",
    "        data=frame_data,\n",
    "        layout=go.Layout(xaxis=dict(range=[0, n_steps]),\n",
    "                         xaxis2=dict(range=[0, n_steps]))\n",
    "    ))\n",
    "\n",
    "# --- Build the initial animated figure ---\n",
    "fig_ev = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\n",
    "        \"Ineffective Policy Function (Always Bet, Negative EV)\",\n",
    "        \"Effective Policy Function (Policy, Positive EV)\"\n",
    "    ),\n",
    "    column_widths=[0.5, 0.5]\n",
    ")\n",
    "\n",
    "# Initial unconditional traces (left)\n",
    "for path in range(n_paths):\n",
    "    fig_ev.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0],\n",
    "            y=[initial_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=2),\n",
    "            opacity=1.0 - path * 0.07,\n",
    "            name='Path' if path == 0 else None,\n",
    "            showlegend=(path == 0)\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "# Initial unconditional expected value line\n",
    "fig_ev.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0],\n",
    "        y=[initial_wealth],\n",
    "        mode='lines',\n",
    "        line=dict(color='orange', dash='dash', width=3),\n",
    "        name='EV (Unconditional, -EV)',\n",
    "        showlegend=True\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Initial conditional traces (right, now positive EV)\n",
    "for path in range(n_paths):\n",
    "    fig_ev.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0],\n",
    "            y=[initial_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='green', width=2),\n",
    "            opacity=1.0 - path * 0.07,\n",
    "            name='Path' if path == 0 else None,\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "# Initial conditional expected value line (positive EV)\n",
    "fig_ev.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0],\n",
    "        y=[initial_wealth],\n",
    "        mode='lines',\n",
    "        line=dict(color='lime', dash='dash', width=3),\n",
    "        name='EV (Conditional, +EV)',\n",
    "        showlegend=True\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig_ev.frames = frames\n",
    "\n",
    "# --- Layout ---\n",
    "fig_ev.update_layout(\n",
    "    height=550,\n",
    "    width=1100,\n",
    "    title_text=\"Ineffective Policy Function vs Effective Policy Function<br><sup>No policy can overcome a negative edge, but with a positive edge, wealth can grow!</sup>\",\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color='white'),\n",
    "    legend=dict(orientation='h', y=-0.15, x=0.5, xanchor='center'),\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.05, 'y': -0.17,\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 30, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig_ev.update_xaxes(title_text=\"Round\", range=[0, n_steps],\n",
    "                    showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "fig_ev.update_yaxes(title_text=\"Wealth\", range=[0, 2000],\n",
    "                    showgrid=True, gridcolor='rgba(128,128,128,0.3)')\n",
    "\n",
    "fig_ev.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cfa918",
   "metadata": {},
   "source": [
    "**Remark:** Acting with an optimal policy function may be easy or difficult depending on the system - but the complexity of $\\pi$ and its time variance does not make the system or game of incomplete information gambling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98548960",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be56497",
   "metadata": {},
   "source": [
    "#### 3.) üçÖ Grocery Shopping and Trading\n",
    "\n",
    "In some systems its easy to act with positive expected value (EV), with an edge (Grocery Shopping)\n",
    "\n",
    "In some systems its hard to act with positive expected value (EV), with an edge (Trading)\n",
    "\n",
    "##### Just because it's hard to act with positive expected value (EV), it does **NOT** make the system *gambling* \n",
    "\n",
    "If you consider trading gambling - you must also consider grocery shopping gambling, let's discuss why\n",
    "\n",
    "If you consider Grocery prices deterministic you must also consider stock prices deterministic\n",
    "\n",
    "We know what the value of the stock prices are on the exchange just like how we know what they are when we go to the store\n",
    "\n",
    "In either case, we don't know what **they are going to be in the future**\n",
    "\n",
    "In either case, acting with positive EV isn't about randomness or uncertainty - its about your policy function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e777a9c",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f217e",
   "metadata": {},
   "source": [
    "##### Example: Maximizing Expected Value (EV) Grocery Shopping\n",
    "\n",
    "Relatively easy, the system is *uncertain* just like trading, we don't know what the price will be before we go into the store\n",
    "\n",
    "We are still operating with a policy function to make optimal decisions under uncertainty,\n",
    "\n",
    "Acting with positive EV is easy, pick the cheaper eggs, pick the bulk option for value you know you will use over time\n",
    "\n",
    " $$\n",
    " \\pi(x) =\n",
    "   \\begin{cases}\n",
    "      x_{\\text{min}}, & x \\leq x^* \\\\\n",
    "      x_{\\text{min}}, & x > x^*\n",
    "    \\end{cases}\n",
    " $$\n",
    " \n",
    " Where $x_{\\text{min}}$ is the point of minimum cost (best price), and $x^*$ is the threshold where buying makes sense.\n",
    " \n",
    " This policy always buys at the minimum cost available (when it's needed).\n",
    " \n",
    " Our Grocery Shopping Edge is now positive.\n",
    " \n",
    " $$\n",
    " \\text{EV}_{\\text{grocery}} = \\mathbb{E}\\big[ R \\mid \\pi \\big] > 0\n",
    " $$\n",
    " \n",
    " Where $\\pi$ is the policy function (decision rule), and the expected value (EV) of grocery shopping under this policy is positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7077aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Parameters ---\n",
    "np.random.seed(42)\n",
    "n_steps = 100\n",
    "n_paths = 7  # number of stochastic sample paths\n",
    "x_vals = np.linspace(-8, 8, 400)\n",
    "\n",
    "# --- Piecewise cost function ---\n",
    "def cost_function(x):\n",
    "    x = np.array(x, dtype=float)\n",
    "    flat_val = 7.0\n",
    "    y = np.full_like(x, flat_val)\n",
    "    inside = (x > -4) & (x < 4)\n",
    "    if inside.any():\n",
    "        # Quadratic between -4 and 4 with min = 5 at x = 4\n",
    "        a = (7 - 5) / ((-4 - 4)**2)  # 2/64 = 0.03125\n",
    "        y[inside] = a * (x[inside] - 4)**2 + 5\n",
    "    y[x <= -4] = flat_val\n",
    "    y[x >= 4] = flat_val\n",
    "    return y.item() if np.isscalar(x) else y\n",
    "\n",
    "# --- Cost baseline ---\n",
    "y_max = 7.0\n",
    "x_noise = np.random.normal(0, 1.5, n_steps)\n",
    "y_costs = cost_function(x_noise)\n",
    "\n",
    "# --- Generate stochastic cumulative savings sample paths ---\n",
    "paths = []\n",
    "for _ in range(n_paths):\n",
    "    drift = np.random.uniform(0.02, 0.08)\n",
    "    volatility = np.random.uniform(0.5, 1.2)\n",
    "    noise = np.random.normal(0, volatility, n_steps)\n",
    "    increments = drift + noise\n",
    "    path = np.cumsum(increments)\n",
    "    paths.append(path)\n",
    "\n",
    "# Pick one arbitrary path to label as \"EV Path\"\n",
    "ev_index = np.random.randint(0, n_paths)\n",
    "\n",
    "# --- Ranges ---\n",
    "y_cost_range = [min(y_costs) - 0.5, y_max + 0.5]\n",
    "wealth_all = np.concatenate(paths)\n",
    "wealth_range = [wealth_all.min() - 5, wealth_all.max() + 5]\n",
    "x_range_wealth = [0, n_steps + 2]\n",
    "\n",
    "# --- Helper to build one frame ---\n",
    "def make_cost_fig(step):\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        column_widths=[0.4, 0.6],\n",
    "        subplot_titles=(\"Grocery Cost Function\", \"Cumulative Savings Sample Paths\")\n",
    "    )\n",
    "\n",
    "    # Left: cost curve\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x_vals,\n",
    "            y=cost_function(x_vals),\n",
    "            mode='lines',\n",
    "            line=dict(color='red', width=4),\n",
    "            name='Cost Function'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Current stochastic point\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[x_noise[step]],\n",
    "            y=[y_costs[step]],\n",
    "            mode='markers',\n",
    "            marker=dict(color='orange', size=14, line=dict(color='white', width=1.5)),\n",
    "            name='Current Cost'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Right: sample paths\n",
    "    for i, path in enumerate(paths):\n",
    "        color = 'magenta' if i == ev_index else 'orange'\n",
    "        dash = 'dash' if i == ev_index else 'solid'\n",
    "        width = 3 if i == ev_index else 2\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=np.arange(1, step+2),\n",
    "                y=path[:step+1],\n",
    "                mode='lines',\n",
    "                line=dict(color=color, width=width, dash=dash),\n",
    "                name=\"EV Path\" if i == ev_index else \"Sample Paths\",\n",
    "                opacity=0.7,\n",
    "                showlegend=(i == ev_index or i == 0)  # only one orange label\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "    # Gridlines\n",
    "    for c in [1, 2]:\n",
    "        fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)', row=1, col=c)\n",
    "        fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)', row=1, col=c)\n",
    "\n",
    "    # Axis labels\n",
    "    fig.update_xaxes(title_text=\"Grocery Quantity / Index\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Cost\", row=1, col=1, range=y_cost_range)\n",
    "    fig.update_xaxes(title_text=\"Time Step\", range=x_range_wealth, row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Cumulative Savings\", range=wealth_range, row=1, col=2)\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        title_text=\"Cost Minimization and Divergent Stochastic Savings Paths\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            x=0.5,\n",
    "            y=-0.22,\n",
    "            xanchor=\"center\",\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "            font=dict(color='white', size=14)\n",
    "        ),\n",
    "        margin=dict(l=50, r=20, b=110, t=70),\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames ---\n",
    "frames = [\n",
    "    go.Frame(\n",
    "        data=make_cost_fig(step).data,\n",
    "        layout=make_cost_fig(step).layout,\n",
    "        name=str(step)\n",
    "    )\n",
    "    for step in range(n_steps)\n",
    "]\n",
    "\n",
    "# --- Initial figure ---\n",
    "fig = make_cost_fig(0)\n",
    "fig.frames = frames\n",
    "\n",
    "# --- Play button ---\n",
    "fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5,\n",
    "        'y': -0.1,\n",
    "        'xanchor': 'center',\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 60, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ee223",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12769eca",
   "metadata": {},
   "source": [
    "##### Is Grocery Shopping Gambling?\n",
    "\n",
    "We can act with negative expected value (EV) or with a negative edge grocery shopping\n",
    "\n",
    "Just because we can make suboptimal decisions with our policy function, it doesn't make the space gambling\n",
    "\n",
    " $$\\pi(x) =\n",
    "  \\begin{cases}\n",
    "     x_{\\text{max}}, & x \\geq x^* \\\\\n",
    "     x_{\\text{max}}, & x < x^*\n",
    "   \\end{cases}$$\n",
    "\n",
    " Where $x_{\\text{max}}$ is the point of maximum cost, and $x^*$ is the necessary threshold.\n",
    "\n",
    " This policy always buys at maximum cost, even when it's unnecessary (below threshold).\n",
    "\n",
    " Our Grocery Shopping Edge is now negative\n",
    "\n",
    " $$\n",
    "\\text{EV}_{\\text{grocery}} = \\mathbb{E}\\big[ R \\mid \\pi \\big] < 0\n",
    "$$\n",
    "\n",
    "where $\\pi$ is the policy function (decision rule) and the expected value (EV) of grocery shopping under this policy is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f690dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Setup for negative EV scenario ---\n",
    "neg_ev_n_steps = 100\n",
    "neg_ev_x_vals = np.linspace(-8, 8, 400)\n",
    "\n",
    "# Cost is always at its max\n",
    "neg_ev_x_noise = np.full(neg_ev_n_steps, 7)  # index doesn't matter since cost always at max\n",
    "neg_ev_y_costs = np.full(neg_ev_n_steps, y_max)\n",
    "\n",
    "# --- Steep negative drift (~ -10 slope total) ---\n",
    "# We can set drift so that total over 100 steps ‚âà -1000\n",
    "# so avg per step ‚âà -10\n",
    "neg_ev_drift = -10.0\n",
    "neg_ev_volatility = 1.5\n",
    "neg_ev_noise = np.random.normal(0, neg_ev_volatility, neg_ev_n_steps)\n",
    "neg_ev_increments = neg_ev_drift + neg_ev_noise\n",
    "neg_ev_path = np.cumsum(neg_ev_increments)\n",
    "\n",
    "# Ranges for axes\n",
    "neg_ev_wealth_range = [neg_ev_path.min() - 50, neg_ev_path.max() + 50]\n",
    "neg_ev_x_range_wealth = [0, neg_ev_n_steps + 2]\n",
    "\n",
    "# --- Helper to build a frame ---\n",
    "def make_neg_ev_fig(step):\n",
    "    fig = make_subplots(\n",
    "        rows=1, cols=2,\n",
    "        column_widths=[0.4, 0.6],\n",
    "        subplot_titles=(\"Grocery Cost Function\", \"Negative EV Savings Path\")\n",
    "    )\n",
    "\n",
    "    # Left: cost curve, highlight only cost at max\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=neg_ev_x_vals,\n",
    "            y=cost_function(neg_ev_x_vals),\n",
    "            mode='lines',\n",
    "            line=dict(color='gray', width=3, dash='dot'),\n",
    "            name='Cost Function',\n",
    "            opacity=0.4\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Always mark the max cost point (show only y_max)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[neg_ev_x_noise[step]],\n",
    "            y=[y_max],\n",
    "            mode='markers',\n",
    "            marker=dict(color='red', size=18, line=dict(color='white', width=2.5)),\n",
    "            name='Always Max Cost'\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Right: Single path with steep negative drift\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=np.arange(1, step+2),\n",
    "            y=neg_ev_path[:step+1],\n",
    "            mode='lines',\n",
    "            line=dict(color='crimson', width=5),\n",
    "            name='Negative EV Path'\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "    # Gridlines and axes\n",
    "    for c in [1, 2]:\n",
    "        fig.update_xaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)', row=1, col=c)\n",
    "        fig.update_yaxes(showgrid=True, gridcolor='rgba(128,128,128,0.3)', row=1, col=c)\n",
    "\n",
    "    fig.update_xaxes(title_text=\"Grocery Quantity / Index\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Cost\", row=1, col=1, range=[y_max - 0.5, y_max + 0.5])\n",
    "    fig.update_xaxes(title_text=\"Time Step\", range=neg_ev_x_range_wealth, row=1, col=2)\n",
    "    fig.update_yaxes(title_text=\"Cumulative Savings\", range=neg_ev_wealth_range, row=1, col=2)\n",
    "\n",
    "    # Layout\n",
    "    fig.update_layout(\n",
    "        height=500,\n",
    "        width=1000,\n",
    "        title_text=\"Indefinite Negative EV: Always Paying Max Cost, Always Losing Money\",\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        font=dict(color='white', size=16),\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            x=0.5, y=-0.18, xanchor=\"center\", orientation=\"h\",\n",
    "            bgcolor='rgba(0,0,0,0)',\n",
    "            font=dict(color='white', size=14)\n",
    "        ),\n",
    "        margin=dict(l=50, r=20, b=100, t=70),\n",
    "    )\n",
    "\n",
    "    return fig\n",
    "\n",
    "# --- Animation frames ---\n",
    "neg_ev_frames = [\n",
    "    go.Frame(\n",
    "        data=make_neg_ev_fig(step).data,\n",
    "        layout=make_neg_ev_fig(step).layout,\n",
    "        name=str(step)\n",
    "    )\n",
    "    for step in range(neg_ev_n_steps)\n",
    "]\n",
    "\n",
    "# --- Initial figure ---\n",
    "neg_ev_fig = make_neg_ev_fig(0)\n",
    "neg_ev_fig.frames = neg_ev_frames\n",
    "\n",
    "# --- Play button ---\n",
    "neg_ev_fig.update_layout(\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.5, 'y': -0.1,\n",
    "        'xanchor': 'center',\n",
    "        'showactive': False,\n",
    "        'buttons': [{\n",
    "            'label': 'Play',\n",
    "            'method': 'animate',\n",
    "            'args': [None, {\n",
    "                'frame': {'duration': 30, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        }]\n",
    "    }]\n",
    ")\n",
    "\n",
    "neg_ev_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222c771",
   "metadata": {},
   "source": [
    "Just because we can act with *negative EV* it doesn't make the system gambling\n",
    "\n",
    "Effectively, we can lose as much money as we want, buying overpriced items, buying things we don't need, wasting, . . ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538603a",
   "metadata": {},
   "source": [
    "###### ______________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f06f96",
   "metadata": {},
   "source": [
    "##### Example: Maximizing EV Trading\n",
    "\n",
    "Is there one fixed way to maximize cost savings over time grocery shopping?  \n",
    "\n",
    "**No**, acting optimally to accumulate max cost savings grocery shopping, the system changes over time (uncertain)\n",
    "\n",
    "Trading oeprates in the same way, there is no one fixed way to accumulate max wealth trading, the system change over time (uncertain)\n",
    "\n",
    "It is far more difficult to achieve an optimal policy $\\pi$ for trading than it is an optimal or positive edge function for grocery shopping \n",
    "\n",
    "**It is only more difficult to act with positive expected value trading than it is grocery shopping - this does not make the system gambling**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5529b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# --- Shared parameters ---\n",
    "n_policies = 100\n",
    "policy_vals = np.linspace(0, 1, n_policies)\n",
    "n_steps = 60\n",
    "n_paths = 8\n",
    "init_wealth = 1000\n",
    "bet_unit = 25\n",
    "\n",
    "policy_ylim_pad = 0.2\n",
    "rng = np.random.default_rng(2025)\n",
    "\n",
    "# Fixed policy for now (~middle)\n",
    "fixed_policy_val = 0.6\n",
    "\n",
    "# Extended list of EV functions, including more random/wiggly cases and various behaviors\n",
    "def random_ev_fn(seed):\n",
    "    rngr = np.random.default_rng(seed)\n",
    "    amps = rngr.uniform(0.05, 0.25, size=5)\n",
    "    freqs = rngr.choice([2, 4, 6, 8, 10, 12], size=5)\n",
    "    phases = rngr.uniform(0, 2*np.pi, size=5)\n",
    "    offset = rngr.uniform(-0.15, 0.15)\n",
    "    quad = rngr.uniform(-1, 1)\n",
    "    base = 0\n",
    "    def f(p):\n",
    "        val = base\n",
    "        for a, f_, ph in zip(amps, freqs, phases):\n",
    "            val += a * np.sin(f_*np.pi*p + ph)\n",
    "        val += offset\n",
    "        val += quad * (p-0.5)**2\n",
    "        return np.clip(val, -0.35, 0.35)\n",
    "    return f\n",
    "\n",
    "ev_func_types = [\n",
    "    dict(name=\"Optimal (positive edge)\",\n",
    "         fn=lambda p: -2.8 * (p - 0.58) ** 2 + 0.20, color=\"royalblue\"),\n",
    "    dict(name=\"Flat (no edge)\",\n",
    "         fn=lambda p: np.zeros_like(p), color=\"gray\"),\n",
    "    dict(name=\"Negative edge\",\n",
    "         fn=lambda p: -1.5 * (p - 0.72) ** 2 - 0.10, color=\"indianred\"),\n",
    "    dict(name=\"Sharp optimal\",\n",
    "         fn=lambda p: -10.0 * (p - 0.45) ** 2 + 0.25, color=\"seagreen\"),\n",
    "    dict(name=\"Wavy/uncertain\",\n",
    "         fn=lambda p: 0.12 * np.sin(12*p) - 0.5*(p-0.5)**2, color=\"orange\"),\n",
    "    dict(name=\"Random EV 1\",\n",
    "         fn=random_ev_fn(1001), color=\"violet\"),\n",
    "    dict(name=\"Random EV 2\",\n",
    "         fn=random_ev_fn(1234), color=\"gold\"),\n",
    "    dict(name=\"Random EV 3\",\n",
    "         fn=random_ev_fn(2025), color=\"lightblue\"),\n",
    "    dict(name=\"Random EV 4\",\n",
    "         fn=random_ev_fn(42), color=\"magenta\"),\n",
    "    dict(name=\"Deeply Negative\",\n",
    "         fn=lambda p: -0.12 - 0.5 * (p-0.6)**2, color=\"firebrick\"),\n",
    "    dict(name=\"Edge Jumps\",\n",
    "         fn=lambda p: np.where(p < 0.4, 0.15, -0.11 + 0.10 * np.sin(5*p)), color=\"lightgreen\"),\n",
    "    dict(name=\"Noisy Center Peak\",\n",
    "         fn=lambda p: 0.22 * np.exp(-20*(p-0.5)**2) + 0.08*np.sin(16*p), color=\"aqua\"),\n",
    "]\n",
    "\n",
    "# Generate random cycle of EV types to create uncertainty, fixed for reproducibility\n",
    "cycle_indices = np.arange(len(ev_func_types))\n",
    "repeat_needed = int(np.ceil(n_steps / len(ev_func_types)))\n",
    "rng_for_cycle = np.random.default_rng(60060)\n",
    "all_cycles = []\n",
    "for _ in range(repeat_needed):\n",
    "    shuffled = rng_for_cycle.permutation(cycle_indices)\n",
    "    all_cycles.append(shuffled)\n",
    "cycle = np.concatenate(all_cycles)[:n_steps]\n",
    "\n",
    "policy_curves = []\n",
    "policy_star_traces = []\n",
    "ev_vals_over_time = []\n",
    "policy_ev_over_time = []\n",
    "\n",
    "for step in range(n_steps):\n",
    "    evf = ev_func_types[cycle[step]]\n",
    "    evs = evf['fn'](policy_vals)\n",
    "    policy_ev = evf['fn'](fixed_policy_val)\n",
    "    ev_vals_over_time.append(evs)\n",
    "    policy_ev_over_time.append(policy_ev)\n",
    "    curve = go.Scatter(\n",
    "        x=policy_vals, y=evs,\n",
    "        mode='lines',\n",
    "        line=dict(color=evf['color'], width=3),\n",
    "        name=None,\n",
    "        xaxis='x', yaxis='y',\n",
    "        showlegend=False\n",
    "    )\n",
    "    star = go.Scatter(\n",
    "        x=[fixed_policy_val], y=[policy_ev],\n",
    "        mode='markers+text',\n",
    "        marker=dict(symbol='star', size=24, color='gold', line=dict(color='black', width=2)),\n",
    "        text=[f'Policy {fixed_policy_val:.2f}'],\n",
    "        textposition='top center',\n",
    "        showlegend=False,\n",
    "        xaxis='x', yaxis='y'\n",
    "    )\n",
    "    policy_curves.append(curve)\n",
    "    policy_star_traces.append(star)\n",
    "\n",
    "# --- Sample Wealth Path Simulation, evolving *one step at a time*, drawing strongly from the left policy EV function ---\n",
    "\n",
    "# For each path, we will keep the array of wealth across all frames so each frame\n",
    "# shows their history up to that round:\n",
    "simulated_path_wealths = np.full((n_paths, n_steps), np.nan)\n",
    "simulated_path_wealths[:, 0] = init_wealth\n",
    "\n",
    "for step in range(1, n_steps):\n",
    "    # Draw current EV function, for computing implied win prob at fixed policy\n",
    "    evf = ev_func_types[cycle[step]]\n",
    "    this_ev = evf['fn'](fixed_policy_val)\n",
    "    if fixed_policy_val > 0.01 and np.abs(bet_unit * fixed_policy_val) > 1e-6:\n",
    "        win_prob = (this_ev / (bet_unit * fixed_policy_val) + 1) / 2\n",
    "        win_prob = np.clip(win_prob, 0, 1)\n",
    "    else:\n",
    "        win_prob = 0.5\n",
    "    for pidx in range(n_paths):\n",
    "        prev_wealth = simulated_path_wealths[pidx, step-1]\n",
    "        # Make a bet with probability = policy (for now, fixed_policy_val); if bet, use win_prob\n",
    "        do_bet = rng.random() < fixed_policy_val\n",
    "        if do_bet:\n",
    "            win = rng.random() < win_prob\n",
    "            change = bet_unit if win else -bet_unit\n",
    "        else:\n",
    "            change = 0\n",
    "        simulated_path_wealths[pidx, step] = prev_wealth + change\n",
    "\n",
    "# ----------- ANIMATION FRAMES (EV function left, sample wealth paths right) --------------\n",
    "frames = []\n",
    "min_ev_glob = min(np.min(ev) for ev in ev_vals_over_time) - 0.05 - policy_ylim_pad\n",
    "max_ev_glob = max(np.max(ev) for ev in ev_vals_over_time) + 0.05 + policy_ylim_pad\n",
    "\n",
    "for i in range(1, n_steps):\n",
    "    frame_data = []\n",
    "    # Left panel: update curve & star\n",
    "    frame_data.append(policy_curves[i])\n",
    "    frame_data.append(policy_star_traces[i])\n",
    "\n",
    "    # Right panel: plot all wealth paths up to i'th round, each path evolves step-by-step\n",
    "    for pidx in range(n_paths):\n",
    "        opacity = 1.0 - pidx * 0.07\n",
    "        frame_data.append(\n",
    "            go.Scatter(\n",
    "                x=np.arange(i + 1),\n",
    "                y=simulated_path_wealths[pidx, :i + 1],\n",
    "                mode='lines',\n",
    "                line=dict(color='yellow', width=2),  # Changed from green to yellow\n",
    "                opacity=opacity,\n",
    "                xaxis='x2', yaxis='y2',\n",
    "                showlegend=False,\n",
    "                name=None\n",
    "            )\n",
    "        )\n",
    "    frames.append(go.Frame(\n",
    "        name=f\"f{i}\",\n",
    "        data=frame_data,\n",
    "        layout=go.Layout(\n",
    "            xaxis=dict(range=[0, 1], showgrid=True, gridcolor='rgba(128,128,128,0.3)'),\n",
    "            yaxis=dict(\n",
    "                range=[min_ev_glob, max_ev_glob],\n",
    "                showgrid=True,\n",
    "                gridcolor='rgba(128,128,128,0.3)'\n",
    "            ),\n",
    "            xaxis2=dict(range=[0, n_steps], showgrid=True, gridcolor='rgba(128,128,128,0.3)'),\n",
    "            yaxis2=dict(range=[0, 2000], showgrid=True, gridcolor='rgba(128,128,128,0.3)'),\n",
    "        )\n",
    "    ))\n",
    "\n",
    "# ----------- FIGURE: 1 row x 2 columns (EV function left, sample paths right) ---------------\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\n",
    "        'EV Function (Randomly Changing Edge, Same Policy)',\n",
    "        f'Sample Wealth Paths (Fixed Policy, EV Function on Left)'\n",
    "    ],\n",
    "    horizontal_spacing=0.15\n",
    ")\n",
    "# Left: EV function at frame 0\n",
    "fig.add_trace(policy_curves[0], row=1, col=1)\n",
    "fig.add_trace(policy_star_traces[0], row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Policy (P(bet))\", range=[0, 1],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=1, col=1)\n",
    "fig.update_yaxes(\n",
    "    title_text=\"Expected Value per Play\",\n",
    "    range=[min_ev_glob, max_ev_glob],\n",
    "    showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "    row=1, col=1)\n",
    "\n",
    "# Right: Wealth paths start with only initial wealth at round 0\n",
    "for pidx in range(n_paths):\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[0],\n",
    "            y=[init_wealth],\n",
    "            mode='lines',\n",
    "            line=dict(color='yellow', width=2),  # Changed from green to yellow\n",
    "            opacity=1.0 - pidx * 0.07,\n",
    "            showlegend=False,\n",
    "            name=None\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "fig.update_xaxes(title_text=\"Round\", range=[0, n_steps],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Wealth\", range=[0, 2000],\n",
    "                 showgrid=True, gridcolor='rgba(128,128,128,0.3)',\n",
    "                 row=1, col=2)\n",
    "\n",
    "# ----------- Layout/Attachment for animation -----------\n",
    "fig.frames = frames\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=1000,\n",
    "    plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)',\n",
    "    font=dict(color='white'),\n",
    "    title_text=\"How Different Random/Changing Edge Functions Alter Outcomes (Fixed Policy)\",\n",
    "    showlegend=False,  # legend removed\n",
    "    updatemenus=[{\n",
    "        'type': 'buttons',\n",
    "        'x': 0.07, 'y': -0.13,\n",
    "        'showactive': False,\n",
    "        'buttons': [dict(\n",
    "            label='Play',\n",
    "            method='animate',\n",
    "            args=[None, {\n",
    "                'frame': {'duration': 40, 'redraw': True},\n",
    "                'fromcurrent': True,\n",
    "                'transition': {'duration': 0}\n",
    "            }]\n",
    "        )]\n",
    "    }]\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6dba82",
   "metadata": {},
   "source": [
    "At one point in time, $\\pi$ is the optimal policy function and we can accumulate significant wealth\n",
    "\n",
    "But over time the policy space changes, and we don't adjust our policy accumulating at first some positive EV then net zero and negative EV\n",
    "\n",
    "**Final Remark:** It is difficult to act with an optimal policy function or even one with positive EV when trading, unlike grocery shopping, that does not make the space gambling - they are both uncertain systems, and our objective is to minimize cost or maximize wealth in the face of uncertainty in either system.  There is not *fixed negative edge* against the agent acting in either system, **neither Trading or Grocery Shopping is gambling**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181d5f8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7b6982",
   "metadata": {},
   "source": [
    "#### 4.) üí≠ Closing Thoughts and Future Topics\n",
    "\n",
    "**TL;DW Executive Summary**\n",
    "- Random variables define a set of possible outcomes with accompanying probabilities and likelihoods\n",
    "- Random variable statistics, probabilities, and distributions converge by the Law of Large Numbers (LLN)\n",
    "- We tend to model uncertain events (non-stationary events or processes) as random variables *even though* quantities lack convergence, leading to a lot of confusion about the efficacy of statistics in the real world for both students and professionals alike\n",
    "- Games of chance and incomplete information are examples systems that impact our wealth over a series of plays or time\n",
    "- In either case, the expected value dictates our wealth path trajectory as we **can never predict** the outcome of any one event\n",
    "- Depending on the structure of the system, our actions may or may not influence our wealth path trajectory - if they don't and there is fixed negative edge, this is gambling - if they do then we are operating in a game of incomplete information and we influence wealth path trajectory\n",
    "- Difficulty of optimizing your optimal policy function does not imply the space itself is gambling, gambling is defined herein as willfully engaging in a system with a fixed negative edge against you, the unconditional edge is equivalent to the conditional one on even an optimal policy function \n",
    "- In other words, no matter what you do you will statistically lose all of your money if you continue to play \n",
    "- If you consider trading gambling due to the difficulting in constructing a productive policy function, then you must necessarily also consider grocery shopping, buying gas for your car, or any other uncertain price or event that enables you to accumulate a wealth path of cost savings \"gambling\" - and that is outrageous\n",
    "\n",
    "\n",
    "**Future Topics**\n",
    "\n",
    "Technical Videos and Other Discussions\n",
    "\n",
    "- Advanced Markov Chains (Absorbing States, Communication Classes, Ergodicity and Stationary Distributions, . . .)\n",
    "- Stochastic Proccesses: Brownian Motion, Arithmetic (additive) Geometric (multiplicative) Brownian Motion\n",
    "- Deriving the Black-Scholes Equation: PDE, Analytical/Numerical Solutions\n",
    "- Kalman Filters and Non-Stationary (A Big Problem in Quant Modeling)\n",
    "- Most Popular Quant Models for Informed Trading\n",
    "- Buy Side vs. Sell Side Quants\n",
    "\n",
    "\n",
    "[Ideas for Interactive Brokers Apps and Tutorials](https://www.interactivebrokers.com/mkt/?src=quantguildY&url=%2Fen%2Fwhyib%2Foverview.php)\n",
    "\n",
    "- Live Kalman Filter Model with Regime Dynamics (MCs/HMMs) \n",
    "- Automated Delta-Neutral Trading System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffacef3b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393cea2",
   "metadata": {},
   "source": [
    "####  $\\text{Copyright ¬© 2025 Quant Guild} \\quad \\quad \\quad \\quad \\text{Author: Roman Paolucci}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
